import numpy as np
from data import training_data, testing_data
import matplotlib.pyplot as plt


def sigmoid(z):
    return 1/(1 - np.exp(-z))


def devsigmoid(z):
    return sigmoid(z)*(1 - sigmoid(z))


def softmax(y):

    exps = np.exp(y)
    sum_exp = np.sum(exps)
    return exps / sum_exp


def crossentropy(a, yhat):
    if yhat == 0:
        e = -np.log(a[0])
    elif yhat == 1:
        e = -np.log(a[1])
    else:
        e = -np.log(a[2])
    return e


def dev_cross_and_soft(a, yhat):
    if yhat == 0:
        dedy = [a[0]-1, a[1], a[2]]
    elif yhat == 1:
        dedy = [a[0], a[1]-1, a[2]]
    else:
        dedy = [a[0], a[1], a[2]-1]
    return dedy


class NN:
    def __init__(self, train, test, learning):
        self.train = train
        self.test = test
        self.learning = learning
        self.inputsize = 3
        self.hiddensize = 10  # 其中一個是bias
        self.outputsize = 3
        self.w0 = np.random.normal(loc=0, scale=0.1, size=(self.inputsize, self.hiddensize-1))
        self.w1 = np.random.normal(loc=0, scale=0.1, size=(self.hiddensize, self.outputsize))

    def forward(self, inputtt, w0, w1):
        z0 = np.reshape(inputtt, (1, 3)).dot(w0)
        y0 = np.append(sigmoid(z0), 0.5)
        z1 = np.reshape(y0, (1, self.hiddensize)).dot(w1)
        y1 = sigmoid(z1*0.99)
        a = softmax(y1)
        parameters = {"z0": z0, "y0": y0, "z1": z1, "y1": y1, "a": a}
        return parameters

    def train_weight(self, i):
        inputt = self.train[0:3, i]
        yhat = self.train[3, i]

        parameters = self.forward(inputt, self.w0, self.w1)

        z0 = parameters["z0"][0]
        y0 = parameters["y0"]
        z1 = parameters["z1"][0]
        y1 = parameters["y1"][0]
        a = parameters["a"][0]

        dedy1 = dev_cross_and_soft(a, yhat)

        dy1dz1 = devsigmoid(z1)
        dedz1 = np.reshape(dedy1*dy1dz1, (1, 3))

        dz1dw1 = np.reshape(y0, (self.hiddensize, 1))

        dw1 = dz1dw1.dot(dedz1)

        dedy0 = dedz1.dot(self.w1[0:self.hiddensize-1, :].T)
        dedz0 = devsigmoid(z0)*dedy0

        dw0 = np.reshape(inputt, (3, 1)).dot(dedz0)
        self.w1 = self.w1 - self.learning*dw1
        self.w0 = self.w0 - self.learning*dw0

        return crossentropy(a, yhat), self.w0, self.w1


nn = NN(train=training_data,test=testing_data, learning=0.008)
parameter = []
for i in range(1470):
    parameter.append(nn.train_weight(i))
parameter = np.array(parameter)
plt.plot(np.arange(0, 1470), parameter[:, 0])
plt.show()
w0, w1 = parameter[np.argmin(parameter[:, 0]), 1:3]

P = []
for i in range(1470):
    p = nn.forward(training_data[0:3, i], w0, w1)
    z = p["a"][0]
    P.append(z)

ll = np.argmax(P, axis=1)
e = np.sum(ll == training_data[3, :])
print(ll)
print(e/1470)
