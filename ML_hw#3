import numpy as np
import matplotlib.pyplot as plt
from data import training_data, testing_data


def sigmoid(z):
    return 1/(1 - np.exp(-z))


def devsigmoid(z):
    return sigmoid(z)*(1 - sigmoid(z))


def onehot(yhat):
    if yhat == 0:
        a = [1, 0, 0]
    elif yhat == 1:
        a = [0, 1, 0]
    else:
        a = [0, 0, 1]
    return a

def softmax(y):

    exps = np.exp(y)
    sum_exp = np.sum(exps)
    return exps / sum_exp


def crossentropy(a, yhat):
    if yhat == 0:
        e = -np.log(a[0])
    elif yhat == 1:
        e = -np.log(a[1])
    else:
        e = -np.log(a[2])
    return e


def dev_cross_and_soft_sigmoid(a, yhat, z1):
    onehott = np.reshape(onehot(yhat), (3, 1))
    dedz = np.reshape(devsigmoid(z1), (3, 1))*(
        np.array([[a[0]-1, a[0], a[0]],
                  [a[1], a[1]-1, a[1]],
                  [a[2], a[2], a[2]-1]]).dot(onehott)
    )

    return dedz


class NN:
    def __init__(self, train, test, learning):
        self.train = train
        self.test = test
        self.learning = learning
        self.inputsize = 3
        self.hiddensize = 10  # 其中一個是bias
        self.outputsize = 3
        self.w0 = np.random.normal(loc=0, scale=0.5, size=(self.inputsize, self.hiddensize-1))
        self.w1 = np.random.normal(loc=0, scale=0.5, size=(self.hiddensize, self.outputsize))
        self.w00 = np.ones((self.inputsize, self.hiddensize-1))/2
        self.w11 = np.ones((self.hiddensize, self.outputsize))/2
        np.save('./weight/w0_'+str(0)+'.npy', self.w0)
        np.save('./weight/w1_'+str(0)+'.npy', self.w1)

    def forward(self, inputtt, w0, w1):
        z0 = np.reshape(inputtt, (1, 3)).dot(w0)
        y0 = np.append(sigmoid(z0), 0.05)
        z1 = np.reshape(y0, (1, self.hiddensize)).dot(w1)
        y1 = sigmoid(z1*0.99)
        a = softmax(y1)
        parameters = {"z0": z0, "y0": y0, "z1": z1, "y1": y1, "a": a}
        return parameters

    def train_weight(self, i):
        inputt = self.train[0:3, i]
        yhat = self.train[3, i]

        w0 = np.load('./weight/w0_'+str(i)+'.npy')
        w1 = np.load('./weight/w1_'+str(i)+'.npy')

        parameters = self.forward(inputt, w0, w1)

        z0 = parameters["z0"][0]
        y0 = parameters["y0"]
        z1 = parameters["z1"][0]
        y1 = parameters["y1"][0]
        a = parameters["a"][0]

        dedz1 = np.reshape(dev_cross_and_soft_sigmoid(a, yhat, z1), (1, 3))

        dz1dw1 = np.reshape(y0, (self.hiddensize, 1))

        dw1 = dz1dw1.dot(dedz1)

        dedy0 = dedz1.dot(w1[0:self.hiddensize-1, :].T)
        dedz0 = devsigmoid(z0)*dedy0

        dw0 = np.reshape(inputt, (3, 1)).dot(dedz0)

        w0 = w0 - self.learning*dw0
        w1 = w1 - self.learning*dw1
        np.save('./weight/w0_'+str(i+1)+'.npy', w0)
        np.save('./weight/w1_'+str(i+1)+'.npy', w1)

        c = crossentropy(a, yhat)
        return c


nn = NN(train=training_data, test=testing_data, learning=0.005)
cost = []
for i in range(1470):
    cost.append(nn.train_weight(i))

plt.plot(np.arange(0, 1470), cost)
plt.show()
